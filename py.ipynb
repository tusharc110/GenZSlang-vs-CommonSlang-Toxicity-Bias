{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gen-Z Slang Toxicity vs. Common English Slang Toxicity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I will use the Perspectives API using Google Cloud to test the Perspectives model for biases. Specifically, I want to test the hypothesis that the Perspective model is less likely to correctly identify toxicity levels when Gen-Z slang is used compared to when a similar phrase that uses general and widely recognized language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing API and Toxicity value scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this cell, I initialize the API client with my API key. I then create a getToxicity definition, which makes a API call to the model with the phrase I want to test for toxicity, to make testing easier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient import discovery\n",
    "import json\n",
    "\n",
    "API_KEY = 'AIzaSyDmXOHBwxWRcy2wO-D91_ZRIvGp3H-_ef8'\n",
    "\n",
    "client = discovery.build(\n",
    "  \"commentanalyzer\",\n",
    "  \"v1alpha1\",\n",
    "  developerKey=API_KEY,\n",
    "  discoveryServiceUrl=\"https://commentanalyzer.googleapis.com/$discovery/rest?version=v1alpha1\",\n",
    "  static_discovery=False,\n",
    ")\n",
    "\n",
    "    \n",
    "def getToxicity(phrase):\n",
    "  analyze_request = {\n",
    "    'comment': { 'text': f'{phrase}' },\n",
    "    'requestedAttributes': {'TOXICITY': {}}\n",
    "  }\n",
    "  jsonResponse = client.comments().analyze(body=analyze_request).execute()\n",
    "  \n",
    "  val = float(jsonResponse['attributeScores']['TOXICITY']['summaryScore']['value'])\n",
    "  \n",
    "  if val < 0.5:\n",
    "        toxicResult = \"Non-Toxic\"\n",
    "  elif val > 0.5:\n",
    "        toxicResult = \"Toxic\"\n",
    "  else:\n",
    "        toxicResult = \"Inconclusive\"\n",
    "  \n",
    "  return f\"[{phrase}] \" + str(val) + \" \" + toxicResult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gathering predicted toxicity data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this cell, I use various queries all developed organically that are sent to the Perspectives model to be assessed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thats a big yikes from me.] 0.05651112 Non-Toxic\n",
      "[Thats a stupid idea.] 0.6667219 Toxic\n",
      "\n",
      "\n",
      "[This song is so ass.] 0.85333383 Toxic\n",
      "[I detest this melody.] 0.33504707 Non-Toxic\n",
      "\n",
      "\n",
      "[This grub is straight-up so horrible.] 0.4475325 Non-Toxic\n",
      "[This food is outright repulsive.] 0.31963667 Non-Toxic\n",
      "\n",
      "\n",
      "[Homies a legit clown.] 0.4977744 Non-Toxic\n",
      "[Hes a bona fide buffoon.] 0.51980776 Toxic\n",
      "\n",
      "\n",
      "[Theyre not just late, theyre last century late.] 0.02779579 Non-Toxic\n",
      "[Their chronic lateness is a flagrant defiance of time.] 0.14429577 Non-Toxic\n",
      "\n",
      "\n",
      "[That movie was so bad omfg.] 0.50503236 Toxic\n",
      "[That cinematic disaster is a masterclass in tedium.] 0.103060275 Non-Toxic\n",
      "\n",
      "\n",
      "[Bros got an ego the size of a planet, no cap ong fr.] 0.2524482 Non-Toxic\n",
      "[Their egomania is a colossal spectacle of self-obsession.] 0.2854835 Non-Toxic\n",
      "\n",
      "\n",
      "[Bro is so stupid hes like the punching bag of the group] 0.8403191 Toxic\n",
      "[Hes the grandmaster of fools, without a doubt.] 0.6588125 Toxic\n",
      "\n",
      "\n",
      "[Bro is allergic to being a good person] 0.28312725 Non-Toxic\n",
      "[He always refrains from being a good person.] 0.112333365 Non-Toxic\n",
      "\n",
      "\n",
      "[Yo mama so fat] 0.7105462 Toxic\n",
      "[Their mother is quite obese.] 0.4977744 Non-Toxic\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(getToxicity('Thats a big yikes from me.')) #Common Gen-Z Toxic Slang\n",
    "print(getToxicity('Thats a stupid idea.')) #Common Toxic English\n",
    "print(\"\\n\")\n",
    "\n",
    "print(getToxicity('This song is so ass.'))  #Gen-Z Toxic Slang\n",
    "print(getToxicity('I detest this melody.')) #Common Toxic English Slang\n",
    "print(\"\\n\")\n",
    "\n",
    "print(getToxicity('This grub is straight-up so horrible.'))\n",
    "print(getToxicity('This food is outright repulsive.'))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(getToxicity('Homies a legit clown.'))\n",
    "print(getToxicity('Hes a bona fide buffoon.'))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(getToxicity('Theyre not just late, theyre last century late.'))\n",
    "print(getToxicity('Their chronic lateness is a flagrant defiance of time.'))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(getToxicity('That movie was so bad omfg.'))\n",
    "print(getToxicity('That cinematic disaster is a masterclass in tedium.'))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(getToxicity('Bros got an ego the size of a planet, no cap ong fr.'))\n",
    "print(getToxicity('Their egomania is a colossal spectacle of self-obsession.'))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(getToxicity('Bro is so stupid hes like the punching bag of the group'))\n",
    "print(getToxicity('Hes the grandmaster of fools, without a doubt.'))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(getToxicity('Bro is allergic to being a good person'))\n",
    "print(getToxicity('He always refrains from being a good person.'))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(getToxicity('Yo mama so fat'))\n",
    "print(getToxicity('Their mother is quite obese.'))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thats totally lit!] 0.042657252 Non-Toxic\n",
      "[What a wonderful idea!] 0.011246625 Non-Toxic\n",
      "\n",
      "\n",
      "[This bop slaps!] 0.20973456 Non-Toxic\n",
      "[This tune is delightful.] 0.027324399 Non-Toxic\n",
      "\n",
      "\n",
      "[Fam, youre looking snatched!] 0.2922276 Non-Toxic\n",
      "[Youre looking exceptionally sharp today.] 0.046368107 Non-Toxic\n",
      "\n",
      "\n",
      "[Your vibe is so dope.] 0.4394682 Non-Toxic\n",
      "[Your presence is very pleasant.] 0.049336795 Non-Toxic\n",
      "\n",
      "\n",
      "[This is the tea, sis!] 0.046120718 Non-Toxic\n",
      "[This is the absolute truth, my friend!] 0.019980038 Non-Toxic\n",
      "\n",
      "\n",
      "[Squad goals asf] 0.18364124 Non-Toxic\n",
      "[A truly admirable team effort.] 0.007351146 Non-Toxic\n",
      "\n",
      "\n",
      "[Your fit is on point!] 0.017466826 Non-Toxic\n",
      "[Your outfit is quite stylish.] 0.054779384 Non-Toxic\n",
      "\n",
      "\n",
      "[Keep it 100, always.] 0.015644746 Non-Toxic\n",
      "[Always stay true to yourself.] 0.025910228 Non-Toxic\n",
      "\n",
      "\n",
      "[We stan a queen!] 0.01017851 Non-Toxic\n",
      "[She is an exemplary leader.] 0.014011159 Non-Toxic\n",
      "\n",
      "\n",
      "[This content is fire!] 0.19219314 Non-Toxic\n",
      "[This material is outstanding.] 0.02543884 Non-Toxic\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(getToxicity('Thats totally lit!')) # Gen-Z Positive Slang\n",
    "print(getToxicity('What a wonderful idea!')) # Common Positive English\n",
    "print(\"\\n\")\n",
    "\n",
    "print(getToxicity('This bop slaps!')) # Gen-Z Positive Slang\n",
    "print(getToxicity('This tune is delightful.')) # Common Positive English\n",
    "print(\"\\n\")\n",
    "\n",
    "print(getToxicity('Fam, youre looking snatched!')) # Gen-Z Positive Slang\n",
    "print(getToxicity('Youre looking exceptionally sharp today.')) # Common Positive English\n",
    "print(\"\\n\")\n",
    "\n",
    "print(getToxicity('Your vibe is so dope.')) \n",
    "print(getToxicity('Your presence is very pleasant.')) \n",
    "print(\"\\n\")\n",
    "\n",
    "print(getToxicity('This is the tea, sis!')) \n",
    "print(getToxicity('This is the absolute truth, my friend!')) \n",
    "print(\"\\n\")\n",
    "\n",
    "print(getToxicity('Squad goals asf')) \n",
    "print(getToxicity('A truly admirable team effort.')) \n",
    "print(\"\\n\")\n",
    "\n",
    "print(getToxicity('Your fit is on point!')) \n",
    "print(getToxicity('Your outfit is quite stylish.')) \n",
    "print(\"\\n\")\n",
    "\n",
    "print(getToxicity('Keep it 100, always.')) \n",
    "print(getToxicity('Always stay true to yourself.')) \n",
    "print(\"\\n\")\n",
    "\n",
    "print(getToxicity('We stan a queen!')) \n",
    "print(getToxicity('She is an exemplary leader.')) \n",
    "print(\"\\n\")\n",
    "\n",
    "print(getToxicity('This content is fire!')) \n",
    "print(getToxicity('This material is outstanding.')) \n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting and Transforming Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this cell, I transform the four categories into four variables, and then map the toxic and non-toxic parameters into 1s and 0s respectively. This ensures that the accuracy method in the next step is able to understand the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "predictedVsActualData = pd.read_csv(\"predictedvsactual.csv\")\n",
    "\n",
    "PvAData_AGen = predictedVsActualData['Actual Toxicity'].iloc[20:40].reset_index(drop=True)\n",
    "PvAData_ACom = predictedVsActualData['Actual Toxicity'].iloc[0:20].reset_index(drop=True)\n",
    "PvAData_PGen = predictedVsActualData['Predicted Toxicity'].iloc[20:40].reset_index(drop=True)\n",
    "PvAData_PCom = predictedVsActualData['Predicted Toxicity'].iloc[0:20].reset_index(drop=True)\n",
    "\n",
    "PvAData_AGen = PvAData_AGen.map({'Toxic': 1, 'Non-Toxic': 0})\n",
    "PvAData_ACom = PvAData_ACom.map({'Toxic': 1, 'Non-Toxic': 0})\n",
    "PvAData_PGen = PvAData_PGen.map({'Toxic': 1, 'Non-Toxic': 0})\n",
    "PvAData_PCom = PvAData_PCom.map({'Toxic': 1, 'Non-Toxic': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing Accuracy and Finalizing Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this cell, I use a accuracy method to determine how accurate the Perspective model is at determining the correct toxicity level. I then use print statements to organize the outputs in a clear way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of toxic english phrases correctly identified: 30.0\n",
      "Percent of toxic GenZ phrases correctly identified: 40.0\n",
      "Percent of non-toxic english phrases correctly identified: 100.0\n",
      "Percent of non-toxic Gen-Z phrases correctly identified: 100.0\n"
     ]
    }
   ],
   "source": [
    "def class_wise_acc(y_actual, y_predicted):\n",
    "    total_p = 0\n",
    "    total_n = 0\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    for i in range(len(y_predicted)):\n",
    "        if y_actual[i] == 1:\n",
    "            total_p += 1\n",
    "            if y_actual[i] == y_predicted[i]:\n",
    "                TP += 1\n",
    "        elif y_actual[i] == 0:\n",
    "            total_n += 1\n",
    "            if y_actual[i] == y_predicted[i]:\n",
    "                TN += 1\n",
    "                \n",
    "    TP_rate = TP / total_p if total_p else 0\n",
    "    TN_rate = TN / total_n if total_n else 0\n",
    "    \n",
    "    return (TP_rate, TN_rate)\n",
    "\n",
    "accuracyToxic_Com, accuracyNonT_Com = class_wise_acc(PvAData_ACom, PvAData_PCom)\n",
    "accuracyToxic_Gen, accuracyNonT_Gen = class_wise_acc(PvAData_AGen, PvAData_PGen)\n",
    "\n",
    "print(\"Percent of toxic english phrases correctly identified: \" + str(accuracyToxic_Com * 100))\n",
    "print(\"Percent of toxic GenZ phrases correctly identified: \" + str(accuracyToxic_Gen * 100))\n",
    "print(\"Percent of non-toxic english phrases correctly identified: \" + str(accuracyNonT_Com * 100))\n",
    "print(\"Percent of non-toxic Gen-Z phrases correctly identified: \" + str(accuracyNonT_Gen * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These numbers mean that 30% of the common toxic english phrases were correctly identified as toxic, and 100% of the positive common english phrases were correctly identified as non-toxic. 40% of the common toxic Gen-Z phrases were correctly identified as toxic, and 100% of the positive Gen-Z phrases were correctly identified as non-toxic. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
